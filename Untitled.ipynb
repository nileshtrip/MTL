{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "import numpy.linalg as la\n",
    "import scipy.optimize\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_angle(B1, B2):\n",
    "    \n",
    "    d, r = B1.shape\n",
    "    svs = la.svd(B1.T @ B2)[1]\n",
    "    cos_theta = min(svs)\n",
    "    sin_theta = math.pow(1-cos_theta**2, 0.5)\n",
    "    \n",
    "    return sin_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigs(M):\n",
    "    \n",
    "    eigenValues, eigenVectors = la.eig(M)\n",
    "\n",
    "    idx = eigenValues.argsort()[::-1]   \n",
    "    eigenValues = eigenValues[idx]\n",
    "    eigenVectors = eigenVectors[:,idx]\n",
    "    \n",
    "    return eigenValues, eigenVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_model(d, r, T, train_n):\n",
    "    \n",
    "    u, s, v = la.svd(np.random.normal(size=(d, r)))\n",
    "    B = u[:, :r]\n",
    "    \n",
    "    train_alphas = [np.random.normal(size=r, scale=1/math.sqrt(r)) for i in range(T)]\n",
    "    train_data=[]\n",
    "    for i in range(T):\n",
    "        X=np.random.normal(size=(train_n, d))\n",
    "        y = X @ B @ train_alphas[i] + 1.0*np.random.normal(size=train_n)\n",
    "        train_data.append((X, y))\n",
    "        \n",
    "    return train_data, B, train_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test_model(d, r, B, test_n):\n",
    "    \n",
    "    alpha = np.random.normal(size=r, scale=1/math.sqrt(r))\n",
    "\n",
    "    X=np.random.normal(size=(test_n, d))\n",
    "    y = X @ B @ alpha + np.random.normal(size=test_n)\n",
    "        \n",
    "    return (X, y), alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_shape(w):\n",
    "    \n",
    "    b=w[:d*r]\n",
    "    v=w[d*r:]\n",
    "    \n",
    "    B = np.reshape(b, (d,r))\n",
    "    V = np.reshape(v, (T,r))\n",
    "    \n",
    "    return B, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_space(B, r):\n",
    "    \n",
    "    u, _, _ = la.svd(B)\n",
    "    \n",
    "    return u[:, 0:r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(weights, train_data):\n",
    "    \n",
    "    \n",
    "    b=weights[:d*r]\n",
    "    v=weights[d*r:]\n",
    "    #print(b)\n",
    "    #print(v.shape)\n",
    "    \n",
    "    B = np.reshape(b, (d,r))\n",
    "    V = np.reshape(v, (T,r))\n",
    "    \n",
    "    loss=0\n",
    "    for t in range(T):\n",
    "        X, y = train_data[t]\n",
    "        loss += 1/(2*m)*np.linalg.norm(y-X @ B @ V[t, :])**2\n",
    "        #print(type(loss))\n",
    "       \n",
    "    loss += 1/8*np.linalg.norm(B.T @ B - V.T @ V, \"fro\")**2\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=250\n",
    "r=5\n",
    "train_n=50\n",
    "T=200\n",
    "test_n=1000\n",
    "\n",
    "m=train_n*T\n",
    "reps=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, B, train_alphas = gen_train_model(d=d, r=r, T=T, train_n=train_n)\n",
    "    \n",
    "B_init = np.random.normal(size=(d,r)).flatten()\n",
    "V_init = np.random.normal(size=(T,r)).flatten()\n",
    "    \n",
    "w = np.concatenate((B_init, V_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = grad(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient(w, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=0\n",
    "# for i in range(1000):\n",
    "#     print(i)\n",
    "#     w -= gradient(w, train_data[0], train_data[1])*.01\n",
    "#     print(loss(w, train_data[0], train_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_init = np.random.normal(size=(d,r)).flatten()\n",
    "V_init = np.random.normal(size=(T,r)).flatten()\n",
    "    \n",
    "w = np.concatenate((B_init, V_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = scipy.optimize.minimize(loss, w, jac=gradient, method='L-BFGS-B', args=train_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 0.3714203442903711\n",
       " hess_inv: <2250x2250 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([-2.26931618e-06, -4.23076707e-06,  5.62542325e-07, ...,\n",
       "       -6.13557927e-08, -3.63622341e-07,  3.05173077e-06])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 457\n",
       "      nit: 428\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([-0.51983461, -0.15019885, -0.01408232, ...,  0.12101937,\n",
       "        0.06899688, -0.25223865])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B_init = np.random.normal(size=(d,r)).flatten()\n",
    "# V_init = np.random.normal(size=(T,r)).flatten()\n",
    "    \n",
    "# w = np.concatenate((B_init, V_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_gd, V_gd = change_shape(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_est = get_col_space(B_gd, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49878860438364775"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sin_angle(B_est, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
