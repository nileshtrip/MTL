{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "import numpy.linalg as la\n",
    "import scipy.optimize\n",
    "import random\n",
    "import math\n",
    "\n",
    "import ray\n",
    "import time\n",
    "import datetime\n",
    "import mkl\n",
    "import os\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 21:12:26,633\tWARNING worker.py:682 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
      "2020-02-03 21:12:26,637\tWARNING services.py:592 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
      "2020-02-03 21:12:26,640\tINFO resource_spec.py:212 -- Starting Ray with 210.16 GiB memory available for workers and up to 18.63 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-02-03 21:12:26,900\tWARNING services.py:1080 -- Failed to start the dashboard. The dashboard requires Python 3 as well as 'pip install aiohttp psutil setproctitle grpcio'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '169.229.49.177',\n",
       " 'redis_address': '169.229.49.177:20774',\n",
       " 'object_store_address': '/tmp/ray/session_2020-02-03_21-12-26_637125_30815/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-02-03_21-12-26_637125_30815/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2020-02-03_21-12-26_637125_30815'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_cpus=48, redis_password=\"123456\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sin_angle(B1, B2):\n",
    "    \n",
    "    d, r = B1.shape\n",
    "    svs = la.svd(B1.T @ B2)[1]\n",
    "    cos_theta = min(svs)\n",
    "    sin_theta = math.pow(1-cos_theta**2, 0.5)\n",
    "    \n",
    "    return sin_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eigs(M):\n",
    "    \n",
    "    eigenValues, eigenVectors = la.eig(M)\n",
    "\n",
    "    idx = eigenValues.argsort()[::-1]   \n",
    "    eigenValues = eigenValues[idx]\n",
    "    eigenVectors = eigenVectors[:,idx]\n",
    "    \n",
    "    return eigenValues, eigenVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_col_space(B, r):\n",
    "    \n",
    "    u, _, _ = la.svd(B)\n",
    "    \n",
    "    return u[:, 0:r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_train_model(d, r, T, train_n):\n",
    "    \n",
    "    u, s, v = la.svd(np.random.normal(size=(d, r)))\n",
    "    B = u[:, :r]\n",
    "    \n",
    "    train_alphas = [np.random.normal(size=r, scale=1/math.sqrt(r)) for i in range(T)]\n",
    "    train_data=[]\n",
    "    for i in range(T):\n",
    "        X=np.random.normal(size=(train_n, d))\n",
    "        y = X @ B @ train_alphas[i] + np.random.normal(size=train_n)\n",
    "        train_data.append((X, y))\n",
    "        \n",
    "    return train_data, B, train_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_test_model(d, r, B, test_n):\n",
    "    \n",
    "    alpha = np.random.normal(size=r, scale=1/math.sqrt(r))\n",
    "\n",
    "    X=np.random.normal(size=(test_n, d))\n",
    "    y = X @ B @ alpha + np.random.normal(size=test_n)\n",
    "        \n",
    "    return (X, y), alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MoM(train_data):\n",
    "    \n",
    "    T = len(train_data)\n",
    "    d = train_data[0][0].shape[1]\n",
    "    \n",
    "    total_n=0\n",
    "    M = np.zeros(shape=(d, d))\n",
    "    for i in range(T):\n",
    "        data = train_data[i]\n",
    "        X, y = data\n",
    "        num = y.shape[0]\n",
    "        total_n += num\n",
    "        scaled_X = (X.T * y).T\n",
    "        M += (scaled_X).T @ scaled_X\n",
    "    M = 1/float(total_n) * M\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rPCA(M, r):\n",
    "    \n",
    "    eigVals, eigVecs = eigs(M)\n",
    "    \n",
    "    return eigVecs[:, :r], eigVecs[:, r:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_shape(w, d, r, T):\n",
    "    \n",
    "    b=w[:d*r]\n",
    "    v=w[d*r:]\n",
    "    \n",
    "    B = np.reshape(b, (d,r))\n",
    "    V = np.reshape(v, (T,r))\n",
    "    \n",
    "    return B, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MS_Loss(weights, train_data, d, r, m):\n",
    "    \n",
    "\n",
    "    T = len(train_data)\n",
    "    \n",
    "    b=weights[:d*r]\n",
    "    v=weights[d*r:]\n",
    "    \n",
    "    B = np.reshape(b, (d,r))\n",
    "    V = np.reshape(v, (T,r))\n",
    "    \n",
    "    loss=0\n",
    "    for t in range(T):\n",
    "        X, y = train_data[t]\n",
    "        loss += 1/(2*m)*np.linalg.norm(y-X @ B @ V[t, :])**2\n",
    "       \n",
    "    loss += 1/8*np.linalg.norm(B.T @ B - V.T @ V, \"fro\")**2\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LR_Loss(weights, test_data):\n",
    "    \n",
    "    X = test_data[0]\n",
    "    y = test_data[1]\n",
    "    \n",
    "    n = y.shape[0]\n",
    "    loss = 1/(2*n)*np.linalg.norm(y-X @ weights)**2\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MetaLR_w_MOM(train_data, r, test_data):\n",
    "    \n",
    "    T = len(train_data)\n",
    "    d = train_data[0][0].shape[1]\n",
    "    \n",
    "    M_est = MoM(train_data)\n",
    "    B1, B2 = rPCA(M_est, r)\n",
    "    \n",
    "    X,y = test_data\n",
    "    X_low = X @ B1\n",
    "    alpha_LR = LR((X_low, y))\n",
    "    beta_LR = B1 @ alpha_LR\n",
    "    \n",
    "    return B1, beta_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MetaLR_w_FO(train_data, r, test_data):\n",
    "    \n",
    "    T = len(train_data)\n",
    "    n, d = train_data[0][0].shape\n",
    "    m = T*n\n",
    "    \n",
    "    ms_gradients = grad(MS_Loss)\n",
    "    \n",
    "    B_init = np.random.normal(size=(d,r)).flatten()\n",
    "    V_init = np.random.normal(size=(T,r)).flatten()\n",
    "    w = np.concatenate((B_init, V_init))\n",
    "    \n",
    "    res_ms = scipy.optimize.minimize(MS_Loss, w, jac=ms_gradients, method='L-BFGS-B', args=(train_data, d, r, m), options = {'max_iter' : 1000})   \n",
    "    B_gd, V_gd = change_shape(res_ms.x, d, r, T)\n",
    "    B1 = get_col_space(B_gd, r)\n",
    "    \n",
    "    X, y = test_data\n",
    "    X_low = X @ B1\n",
    "    test_data_new = [X_low, y]\n",
    "    \n",
    "    test_gradients = grad(LR_Loss)\n",
    "    \n",
    "    w = np.random.normal(size=r).flatten()\n",
    "    res_test = scipy.optimize.minimize(LR_Loss, w, jac=test_gradients, method='L-BFGS-B', max_iter args=(test_data_new), options = {'max_iter' : 1000})  \n",
    "    alpha_LR = res_test.x\n",
    "    \n",
    "    beta_LR = B1 @ alpha_LR\n",
    "    \n",
    "    return B1, beta_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LR(test_data):\n",
    "    \n",
    "    X, y = test_data\n",
    "    beta_LR = la.pinv((X.T @ X)) @ X.T @ y\n",
    "    \n",
    "    return beta_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def run_expt(d, r, T, train_n, test_n, seed):\n",
    "    \n",
    "    mkl.set_num_threads(4)\n",
    "    np.random.seed(seed)\n",
    "    train_data, B, train_alphas = gen_train_model(d=d, r=r, T=T, train_n=train_n)\n",
    "    test_data, alpha_test = gen_test_model(d, r, B, test_n)\n",
    "    \n",
    "    B_meta_mom, beta_meta_LR_mom = MetaLR_w_MOM(train_data, r, test_data)\n",
    "    sin_theta_mom = sin_angle(B_meta_mom, B)\n",
    "    \n",
    "    B_meta_fo, beta_meta_LR_fo = MetaLR_w_FO(train_data, r, test_data)\n",
    "    sin_theta_fo = sin_angle(B_meta_fo, B)\n",
    "    \n",
    "    beta_LR = LR(test_data)\n",
    "    beta_true = B @ alpha_test\n",
    "\n",
    "    return np.linalg.norm(beta_meta_LR_mom-beta_true), np.linalg.norm(beta_meta_LR_fo-beta_true), np.linalg.norm(beta_LR-beta_true), sin_theta_mom, sin_theta_fo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_parallel_expt(d, r, T, train_n, test_n, reps):\n",
    "    \n",
    "    meta_LR_errs=[]\n",
    "    meta_RR_errs=[]\n",
    "    LR_errs=[]\n",
    "    ridge_errs=[]\n",
    "    seeds = [i for i in range(reps)]\n",
    "\n",
    "    data = ray.get([run_expt.remote(d, r, T, train_n, test_n, seeds[num]) for num in range(reps)])\n",
    "    meta_LR_mom_errs, meta_LR_fo_errs, beta_LR_errs, sin_theta_mom, sin_theta_fo = zip(*data)\n",
    "    \n",
    "    return meta_LR_mom_errs, meta_LR_fo_errs, beta_LR_errs, sin_theta_mom, sin_theta_fo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First Experiment with Large Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=100\n",
    "r=5\n",
    "train_n=5\n",
    "test_n=2500\n",
    "reps=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T_list = [100, 200, 400, 800, 1600, 3200, 6400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collect_data_T(d, r, T_list, train_n, test_n, reps):\n",
    "    \n",
    "    metaLRmommus=[]\n",
    "    metaLRmomstd=[]\n",
    "    \n",
    "    metaLRfomus=[]\n",
    "    metaLRfostd=[]\n",
    "    \n",
    "    betaLRmus=[]\n",
    "    betaLRstds=[]\n",
    "\n",
    "    sinthetamommus=[]\n",
    "    sinthetamomstd=[]\n",
    "    \n",
    "    sinthetafomus=[]\n",
    "    sinthetafostd=[]\n",
    "    \n",
    "    for t in T_list:\n",
    "        print(t)\n",
    "        meta_LR_mom_errs, meta_LR_fo_errs, beta_LR_errs, sin_theta_mom, sin_theta_fo = run_parallel_expt(d, r, t, train_n, test_n, reps)\n",
    "\n",
    "        metaLRmommus.append(np.mean(meta_LR_mom_errs))\n",
    "        metaLRmomstd.append(np.std(meta_LR_mom_errs)) \n",
    "\n",
    "        metaLRfomus.append(np.mean(meta_LR_fo_errs))\n",
    "        metaLRfostd.append(np.std(meta_LR_fo_errs)) \n",
    "        \n",
    "        betaLRmus.append(np.mean(beta_LR_errs))\n",
    "        betaLRstds.append(np.std(beta_LR_errs))\n",
    "\n",
    "        sinthetamommus.append(np.mean(sin_theta_mom))\n",
    "        sinthetamomstd.append(np.std(sin_theta_mom)) \n",
    "\n",
    "        sinthetafomus.append(np.mean(sin_theta_fo))\n",
    "        sinthetafostd.append(np.std(sin_theta_fo)) \n",
    "        \n",
    "    return (metaLRmommus, metaLRmomstd), (metaLRfomus, metaLRfostd), (betaLRmus, betaLRstds), (sinthetamommus, sinthetamomstd), (sinthetafomus, sinthetafostd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metaLRmom, metaLRfo, betaLR, sinthetamom, sinthetafo = collect_data_T(d, r, T_list, train_n, test_n, reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_data = {\"metaLRmom\" : metaLRmom, \"metaLRfo\" :  metaLRfo, \"betaLR\" : betaLR, \"sinthetamom\" : sinthetamom, \"sinthetafo\" : sinthetafo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_data[\"T_list\"] =  T_list\n",
    "save_data[\"d\"] = d\n",
    "save_data[\"r\"] = r\n",
    "save_data[\"train_n\"] = train_n\n",
    "save_data[\"test_n\"] = test_n\n",
    "save_data[\"reps\"] = reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = \"d=\"+str(d)+\",r=\"+str(r)+\",train_n=\"+str(train_n)+\",test_n=\"+str(test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"Meta,\"+str(params)+\".pickle\"\n",
    "folder_name = \"Data\"\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "pickle.dump(save_data, open(file_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Second Experiment with Small Train Set and Small Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=100\n",
    "r=5\n",
    "train_n=25\n",
    "test_n=25\n",
    "reps=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metaLRmom, metaLRfo, betaLR, sinthetamom, sinthetafo = collect_data_T(d, r, T_list, train_n, test_n, reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_data = {\"metaLRmom\" : metaLRmom, \"metaLRfo\" :  metaLRfo, \"betaLR\" : betaLR, \"sinthetamom\" : sinthetamom, \"sinthetafo\" : sinthetafo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_data[\"T_list\"] =  T_list\n",
    "save_data[\"d\"] = d\n",
    "save_data[\"r\"] = r\n",
    "save_data[\"train_n\"] = train_n\n",
    "save_data[\"test_n\"] = test_n\n",
    "save_data[\"reps\"] = reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = \"d=\"+str(d)+\",r=\"+str(r)+\",train_n=\"+str(train_n)+\",test_n=\"+str(test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"Meta,\"+str(params)+\".pickle\"\n",
    "folder_name = \"Data\"\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "pickle.dump(save_data, open(file_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Third Experiment Varying Training_n but with small number of Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=100\n",
    "r=5\n",
    "T=20\n",
    "test_n=50\n",
    "reps=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_n_list = [100, 200, 400, 800, 1600, 3200, 6400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collect_data_n(d, r, t, train_n_list, test_n, reps):\n",
    "    \n",
    "    metaLRmommus=[]\n",
    "    metaLRmomstd=[]\n",
    "    \n",
    "    metaLRfomus=[]\n",
    "    metaLRfostd=[]\n",
    "    \n",
    "    betaLRmus=[]\n",
    "    betaLRstds=[]\n",
    "\n",
    "    sinthetamommus=[]\n",
    "    sinthetamomstd=[]\n",
    "    \n",
    "    sinthetafomus=[]\n",
    "    sinthetafostd=[]\n",
    "    \n",
    "    for train_n in train_n_list:\n",
    "        print(train_n)\n",
    "        meta_LR_mom_errs, meta_LR_fo_errs, beta_LR_errs, sin_theta_mom, sin_theta_fo = run_parallel_expt(d, r, t, train_n, test_n, reps)\n",
    "\n",
    "        metaLRmommus.append(np.mean(meta_LR_mom_errs))\n",
    "        metaLRmomstd.append(np.std(meta_LR_mom_errs)) \n",
    "\n",
    "        metaLRfomus.append(np.mean(meta_LR_fo_errs))\n",
    "        metaLRfostd.append(np.std(meta_LR_fo_errs)) \n",
    "        \n",
    "        betaLRmus.append(np.mean(beta_LR_errs))\n",
    "        betaLRstds.append(np.std(beta_LR_errs))\n",
    "\n",
    "        sinthetamommus.append(np.mean(sin_theta_mom))\n",
    "        sinthetamomstd.append(np.std(sin_theta_mom)) \n",
    "\n",
    "        sinthetafomus.append(np.mean(sin_theta_fo))\n",
    "        sinthetafostd.append(np.std(sin_theta_fo)) \n",
    "        \n",
    "    return (metaLRmommus, metaLRmomstd), (metaLRfomus, metaLRfostd), (betaLRmus, betaLRstds), (sinthetamommus, sinthetamomstd), (sinthetafomus, sinthetafostd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'run_parallel_expt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-212ccedc3896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetaLRmom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetaLRfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetaLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msinthetamom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msinthetafo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_data_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_n_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-7b8f185ac2d3>\u001b[0m in \u001b[0;36mcollect_data_n\u001b[0;34m(d, r, t, train_n_list, test_n, reps)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_n_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmeta_LR_mom_errs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_LR_fo_errs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_LR_errs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msin_theta_mom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msin_theta_fo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_parallel_expt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmetaLRmommus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_LR_mom_errs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_parallel_expt' is not defined"
     ]
    }
   ],
   "source": [
    "metaLRmom, metaLRfo, betaLR, sinthetamom, sinthetafo = collect_data_n(d, r, T, train_n_list, test_n, reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metaLRmom' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-62b237a53d19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"metaLRmom\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmetaLRmom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"metaLRfo\"\u001b[0m \u001b[0;34m:\u001b[0m  \u001b[0mmetaLRfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"betaLR\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbetaLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sinthetamom\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0msinthetamom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sinthetafo\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0msinthetafo\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'metaLRmom' is not defined"
     ]
    }
   ],
   "source": [
    "save_data = {\"metaLRmom\" : metaLRmom, \"metaLRfo\" :  metaLRfo, \"betaLR\" : betaLR, \"sinthetamom\" : sinthetamom, \"sinthetafo\" : sinthetafo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_data[\"train_n_list\"] =  train_n_list\n",
    "save_data[\"d\"] = d\n",
    "save_data[\"r\"] = r\n",
    "save_data[\"T\"] = T\n",
    "save_data[\"test_n\"] = test_n\n",
    "save_data[\"reps\"] = reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = \"d=\"+str(d)+\",r=\"+str(r)+\",T=\"+str(T)+\",test_n=\"+str(test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"Meta,\"+str(params)+\".pickle\"\n",
    "folder_name = \"Data\"\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "pickle.dump(save_data, open(file_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
